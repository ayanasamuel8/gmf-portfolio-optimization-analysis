# ğŸ“ˆ GMF Time Series Forecasting & Portfolio Optimization

![alt text](https://img.shields.io/badge/python-3.10+-blue.svg)
![alt text](https://img.shields.io/badge/License-MIT-yellow.svg)

An end-to-end quantitative analysis project to enhance portfolio management strategies for Guide Me in Finance (GMF) Investments. This repository documents the process of fetching financial data, developing predictive time series models, and constructing an optimal investment portfolio based on Modern Portfolio Theory (MPT).

---

## ğŸ¯ Project Overview

As a Financial Analyst at GMF Investments, the objective is to leverage data-driven insights to optimize client portfolios. This project utilizes historical financial data for three key assets with distinct risk profiles:

* **Tesla (TSLA):** High-growth, high-volatility stock.
* **S\&P 500 ETF (SPY):** Diversified, moderate-risk market benchmark.
* **Vanguard Total Bond Market ETF (BND):** Stable, low-risk bond fund.

By forecasting future trends and understanding asset correlations, we aim to build a portfolio that maximizes returns for a given level of risk, grounded in proven financial theories.

---

## âœ¨ Key Features

* ğŸ“¦ **Automated Data Ingestion** â€“ Fetches over a decade of financial data using the `yfinance` API.
* ğŸ“Š **In-Depth EDA** â€“ Analysis of price trends, volatility, return distributions, and risk metrics.
* ğŸ¤– **Advanced Time Series Forecasting** â€“ ARIMA and LSTM models for predictive analysis.
* âš™ï¸ **Portfolio Optimization (MPT)** â€“ Efficient Frontier, Maximum Sharpe Ratio, and Minimum Volatility portfolios.
* ğŸ§ª **Backtesting** â€“ Compare optimized portfolio performance with a benchmark strategy.

---

## ğŸš€ Project Roadmap

### âœ… Completed: Task 1 â€“ Preprocessing & Exploration

* Ingested, cleaned, and analyzed historical data (July 2015 â€“ July 2025).
* Key EDA insights:

  * TSLA shows explosive growth and volatility.
  * SPY is stable, upward-trending.
  * BND is low volatility, portfolio stabilizer.
  * VaR (95%) of equally weighted portfolio: **-3.12%**.

### â¡ï¸ Next Steps:

#### ğŸ§  Task 2: Time Series Forecasting

* Build ARIMA and LSTM models for TSLA price forecasting.
* Evaluate with RMSE & MAE.

#### ğŸ”® Task 3: Forecast Future Market Trends

* Use best-performing model for 6â€“12 month forecast.
* Include confidence intervals.

#### ğŸ¯ Task 4: Portfolio Optimization

* Combine TSLA forecast returns with historical SPY & BND.
* Use covariance matrix + MPT for Efficient Frontier.
* Identify max Sharpe ratio and min volatility portfolios.

#### ğŸ“œ Task 5: Backtesting

* Compare optimized portfolio vs 60/40 SPY/BND benchmark.
* Assess performance improvement.

---

## ğŸ” EDA Highlights

* **Price Trends & Volatility:**
  TSLA volatility spikes (esp. 2020â€“2021) are much higher than SPY and BND.

* **Return Distributions:**
  All assets have fat-tailed return distributions.
  TSLAâ€™s is widest (high risk), BNDâ€™s is narrowest (low risk).

* **Value at Risk (VaR):**
  95% VaR of -3.12% for equally weighted portfolio.

---

## ğŸ—‚ Project Structure

```
gmf-portfolio-optimization-analysis/
â”‚
â”œâ”€â”€ .github/              # GitHub Actions for CI/CD
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/              # Raw data from yfinance
â”‚
â”œâ”€â”€ notebooks/            # Jupyter Notebooks for analysis
â”‚   â””â”€â”€ 1.0-data-exploration.ipynb
â”‚
â”œâ”€â”€ reports/              # Final reports & figures
â”‚
â”œâ”€â”€ src/                  # Source code
â”‚   â”œâ”€â”€ data_ingestion.py # Script to fetch data
â”‚   â””â”€â”€ utils.py          # Helper functions
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ›  Setup & Installation

1. **Clone Repository**

```bash
git clone https://github.com/your-username/gmf-portfolio-optimization-analysis.git
cd gmf-portfolio-optimization-analysis
```

2. **Create Virtual Environment**

**Windows:**

```bash
python -m venv venv
.\venv\Scripts\Activate
```

**macOS / Linux:**

```bash
python3 -m venv venv
source venv/bin/activate
```

3. **Install Dependencies**

```bash
pip install -r requirements.txt
```

---

## ğŸš€ How to Use

**Step 1 â€“ Data Ingestion:**

```bash
python src/data_ingestion.py
```

This populates `data/raw/` with CSV files.

**Step 2 â€“ Run Analysis:**

```bash
jupyter lab
```

Open `notebooks/1.0-data-exploration.ipynb` and run cells.

---

## ğŸ’» Technologies Used

* **Python 3.10+**
* **Libraries:**

  * Data: `pandas`, `numpy`, `yfinance`
  * Visualization: `matplotlib`, `seaborn`
  * Time Series: `statsmodels`, `pmdarima`, `tensorflow`
  * Optimization: `PyPortfolioOpt`
  * Utilities: `scikit-learn`
